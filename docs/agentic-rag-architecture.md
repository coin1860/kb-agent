# Agentic RAG Architecture â€” Deep Dive

> **Last Updated**: 2026-03-01
> **Status**: Production (Post adaptive-rag-optimization refactor)

## Overview

KB Agent é‡‡ç”¨ **6 èŠ‚ç‚¹è‡ªé€‚åº” CRAG (Corrective RAG)** æ‹“æ‰‘ï¼Œç”± [LangGraph](https://github.com/langchain-ai/langgraph) StateGraph é©±åŠ¨ã€‚æ¯æ¬¡ç”¨æˆ·æŸ¥è¯¢ä¼šç»è¿‡ã€Œæ„å›¾åˆ†æ â†’ å·¥å…·è§„åˆ’ â†’ å·¥å…·æ‰§è¡Œ â†’ è¯æ®è¯„åˆ† â†’ ç”Ÿæˆåˆæˆã€çš„é—­ç¯æµç¨‹ï¼Œå¹¶åœ¨è¯æ®è´¨é‡ä¸è¶³æ—¶è‡ªåŠ¨é‡è¯•ã€‚

---

## Flow Diagram

```mermaid
graph TD
    Start(["ğŸ¯ User Query"]) --> Analyze

    subgraph "LangGraph StateGraph (max 3 iterations)"
        Analyze["ğŸ§­ analyze_and_route<br/>æ„å›¾åˆ†ç±» + æŸ¥è¯¢åˆ†è§£<br/><i>LLM Call #1</i>"]
        Plan["ğŸ§  plan<br/>å·¥å…·é€‰æ‹©ä¸å‚æ•°è§„åˆ’<br/><i>LLM Call #2</i>"]
        ToolExec["ğŸ” tool_exec<br/>Execute Supported Tools:<br/>- hybrid_search<br/>- vector_search<br/>- grep_search<br/>- local_file_qa<br/>- read_file<br/>- graph_related<br/>- jira_fetch<br/>- confluence_fetch<br/>- web_fetch<br/>- index_command<br/><i>No LLM Call</i>"]
        Grade["âš–ï¸ grade_evidence<br/>CRAG è¯æ®è¯„åˆ†<br/><i>LLM Call #3</i>"]
        Synth["âœ¨ synthesize<br/>å¸¦å¼•ç”¨çš„ç­”æ¡ˆç”Ÿæˆ<br/><i>LLM Call #4</i>"]

        Analyze --> Plan
        Plan --> ToolExec
        ToolExec --> Grade

        Grade -->|"âœ… GENERATE<br/>avg â‰¥ 0.7"| Synth
        Grade -->|"ğŸ”„ REFINE<br/>0.3 â‰¤ avg < 0.7<br/>& iter < 3"| Plan
        Grade -->|"ğŸ—‘ï¸ RE_RETRIEVE<br/>avg < 0.3<br/>& iter < 3"| Analyze
        Grade -->|"â±ï¸ Max Iterations<br/>iter â‰¥ 3"| Synth
    end

    Synth --> Mask["ğŸ›¡ï¸ Security Masking"]
    Mask --> End(["ğŸ“ Final Answer<br/>(with citations)"])

    style Start fill:#e1bee7,stroke:#7b1fa2,stroke-width:2px,color:#000
    style End fill:#e1bee7,stroke:#7b1fa2,stroke-width:2px,color:#000
    style Analyze fill:#e3f2fd,stroke:#1565c0,color:#000
    style Plan fill:#e3f2fd,stroke:#1565c0,color:#000
    style ToolExec fill:#e8f5e9,stroke:#2e7d32,color:#000
    style Grade fill:#fff3e0,stroke:#ef6c00,color:#000
    style Synth fill:#fce4ec,stroke:#c62828,color:#000
    style Mask fill:#f3e5f5,stroke:#6a1b9a,color:#000
```

---

## Nodes Detail

### Node 1: `analyze_and_route` (æ„å›¾åˆ†æ)

| å±æ€§ | å€¼ |
|------|----| 
| æºæ–‡ä»¶ | `agent/nodes.py:225` |
| LLM è°ƒç”¨ | âœ… 1 æ¬¡ |
| è¾“å…¥ | `query`, `messages` |
| è¾“å‡º | `query_type`, `sub_questions`, `routing_plan` |

**åŠŸèƒ½**: å°†ç”¨æˆ·æŸ¥è¯¢åˆ†ç±»ä¸º 4 ç§æ„å›¾ä¹‹ä¸€ï¼Œå¹¶å»ºè®®æœ€ä¼˜å·¥å…·ç»„åˆï¼š

| Intent Type | é¦–é€‰å·¥å…· | ç¤ºä¾‹æŸ¥è¯¢ |
|---|---|---|
| `exact` | `grep_search` | "PROJ-123 çŠ¶æ€", "KB_AGENT_MAX_ITERATIONS" |
| `conceptual` | `vector_search` / `hybrid_search` | "ç´¢å¼•æµæ°´çº¿æ€ä¹ˆå·¥ä½œçš„ï¼Ÿ" |
| `relational` | `graph_related` | "PROJ-100 å…³è”äº†å“ªäº› ticketï¼Ÿ" |
| `file_discovery` | `local_file_qa` | "æŸ¥æ‰¾å…³äºè®¤è¯çš„æ–‡ä»¶" |

---

### Node 2: `plan` (å·¥å…·è§„åˆ’)

| å±æ€§ | å€¼ |
|------|----| 
| æºæ–‡ä»¶ | `agent/nodes.py:303` |
| LLM è°ƒç”¨ | âœ… 1 æ¬¡ |
| è¾“å…¥ | `query`, `routing_plan`, `context`, `tool_history` |
| è¾“å‡º | `pending_tool_calls` |

**åŠŸèƒ½**: æ ¹æ® `routing_plan` å’Œå·²æœ‰ `context`ï¼ŒLLM å†³å®šä¸‹ä¸€æ­¥è¦è°ƒç”¨å“ªäº›å·¥å…·åŠå…¶å‚æ•°ã€‚è¾“å‡ºä¸º JSON æ•°ç»„ `[{name, args}]`ã€‚

---

### Node 3: `tool_exec` (å·¥å…·æ‰§è¡Œ)

| å±æ€§ | å€¼ |
|------|----| 
| æºæ–‡ä»¶ | `agent/nodes.py:512` |
| LLM è°ƒç”¨ | âŒ æ—  |
| è¾“å…¥ | `pending_tool_calls` |
| è¾“å‡º | `context` (è¿½åŠ ), `tool_history` |

**åŠŸèƒ½**: é€ä¸ªæ‰§è¡Œ `plan` èŠ‚ç‚¹å®‰æ’çš„å·¥å…·è°ƒç”¨ï¼Œå°†ç»“æœè¿½åŠ åˆ° `context`ã€‚æ¯æ¡ç»“æœå¸¦æœ‰ `[SOURCE:path:L{line}]` å‰ç¼€ï¼Œç”¨äºåç»­å¼•ç”¨è¿½è¸ªã€‚

**å¯ç”¨å·¥å…· (9 ä¸ª)**:

```mermaid
graph LR
    subgraph "Keyword Search"
        A["grep_search<br/>ripgrep + BM25"]
    end
    subgraph "Semantic Search"
        B["vector_search<br/>ChromaDB"]
    end
    subgraph "Hybrid"
        C["hybrid_search<br/>BM25 + Vector â†’ RRF"]
    end
    subgraph "Knowledge Graph"
        D["graph_related<br/>NetworkX"]
    end
    subgraph "File Operations"
        E["read_file"]
        F["local_file_qa"]
        J["index_command"]
    end
    subgraph "External"
        G["jira_fetch"]
        H["confluence_fetch"]
        I["web_fetch"]
    end

    style A fill:#e8f5e9,stroke:#2e7d32,color:#000
    style B fill:#e3f2fd,stroke:#1565c0,color:#000
    style C fill:#fff9c4,stroke:#f9a825,color:#000
    style D fill:#f3e5f5,stroke:#6a1b9a,color:#000
    style E fill:#fce4ec,stroke:#c62828,color:#000
    style F fill:#fce4ec,stroke:#c62828,color:#000
    style G fill:#fff3e0,stroke:#ef6c00,color:#000
    style H fill:#fff3e0,stroke:#ef6c00,color:#000
    style I fill:#fff3e0,stroke:#ef6c00,color:#000
    style J fill:#fce4ec,stroke:#c62828,color:#000
```

---

### Node 4: `grade_evidence` (CRAG è¯æ®è¯„åˆ†)

| å±æ€§ | å€¼ |
|------|----| 
| æºæ–‡ä»¶ | `agent/nodes.py:633` |
| LLM è°ƒç”¨ | âœ… 1 æ¬¡ (æ‰¹é‡è¯„åˆ†) |
| è¾“å…¥ | `query`, `context` |
| è¾“å‡º | `evidence_scores`, `grader_action`, `context` (è¿‡æ»¤å) |

**åŠŸèƒ½**: å¯¹æ¯æ¡ evidence æ‰“åˆ† (0.0-1.0)ï¼Œè¿‡æ»¤ä½åˆ†é¡¹ (< 0.3)ï¼Œå¹¶æ ¹æ®å¹³å‡åˆ†å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼š

```mermaid
graph LR
    Score["avg(scores)"] -->|"â‰¥ 0.7"| Gen["âœ… GENERATE<br/>â†’ synthesize"]
    Score -->|"0.3 ~ 0.7"| Ref["ğŸ”„ REFINE<br/>â†’ plan<br/>(ä¿ç•™é«˜åˆ†è¯æ®)"]
    Score -->|"< 0.3"| Re["ğŸ—‘ï¸ RE_RETRIEVE<br/>â†’ analyze_and_route<br/>(æ¢ç­–ç•¥)"]

    style Gen fill:#c8e6c9,stroke:#2e7d32,color:#000
    style Ref fill:#fff9c4,stroke:#f9a825,color:#000
    style Re fill:#ffcdd2,stroke:#c62828,color:#000
```

---

### Node 5: `synthesize` (ç­”æ¡ˆåˆæˆ)

| å±æ€§ | å€¼ |
|------|----| 
| æºæ–‡ä»¶ | `agent/nodes.py:743` |
| LLM è°ƒç”¨ | âœ… 1 æ¬¡ |
| è¾“å…¥ | `query`, `context`, `messages` |
| è¾“å‡º | `final_answer` |

**åŠŸèƒ½**: åŸºäºè¿‡æ»¤åçš„ evidence ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆï¼Œå¼ºåˆ¶è¦æ±‚ï¼š
- **Anti-Hallucination**: åªèƒ½ä½¿ç”¨æä¾›çš„è¯æ® â€” ç¦æ­¢ä½¿ç”¨è‡ªèº«çŸ¥è¯†
- **Citations**: å†…è”è„šæ³¨ `[1]`, `[2]` + æœ«å°¾ References åŒºåŸŸ
- **No-Evidence Refusal**: æ— è¯æ®æ—¶ç›´æ¥æ‹’ç»å›ç­”

---

## LLM API è°ƒç”¨åˆ†æ

è¿™æ˜¯å½“å‰æœ€å¤§çš„æ€§èƒ½ç“¶é¢ˆã€‚æ¯æ¬¡ç”¨æˆ·æŸ¥è¯¢çš„ LLM è°ƒç”¨æ¬¡æ•°ï¼š

| åœºæ™¯ | LLM Calls | å·¥å…·è°ƒç”¨ | æ€»è€—æ—¶ä¼°è®¡ |
|------|-----------|----------|-----------|
| **Best Case** (ä¸€è½®å‘½ä¸­) | 4 | 1-2 | ~4-6s |
| **REFINE** (ä¸€è½®ç²¾åŒ–) | 7 | 2-4 | ~8-12s |
| **RE_RETRIEVE** (é‡æ–°æ£€ç´¢) | 8 | 3-6 | ~10-15s |
| **Worst Case** (3 è½®è¿­ä»£) | 12 | 6-9 | ~15-20s |

```mermaid
sequenceDiagram
    participant U as User
    participant E as Engine
    participant LLM as LLM API
    participant T as Tools

    U->>E: "ç´¢å¼•æµæ°´çº¿æ€ä¹ˆå·¥ä½œçš„ï¼Ÿ"
    
    Note over E: --- Iteration 1 ---
    E->>LLM: ğŸ§­ analyze_and_route (Call #1)
    LLM-->>E: {type: conceptual, tools: [hybrid_search]}
    E->>LLM: ğŸ§  plan (Call #2)
    LLM-->>E: [{name: hybrid_search, args: {query: ...}}]
    E->>T: ğŸ” hybrid_search (grep + vector + RRF)
    T-->>E: [context items with SOURCE tags]
    E->>LLM: âš–ï¸ grade_evidence (Call #3)
    LLM-->>E: [0.8, 0.6, 0.2] â†’ avg=0.53 â†’ REFINE

    Note over E: --- Iteration 2 (REFINE) ---
    E->>LLM: ğŸ§  plan (Call #4)
    LLM-->>E: [{name: read_file, args: {path: ...}}]
    E->>T: ğŸ“„ read_file
    T-->>E: [full file content]
    E->>LLM: âš–ï¸ grade_evidence (Call #5)
    LLM-->>E: [0.9, 0.8] â†’ avg=0.85 â†’ GENERATE

    Note over E: --- Generate ---
    E->>LLM: âœ¨ synthesize (Call #6)
    LLM-->>E: "ç­”æ¡ˆ [1]...\n---\n[1] docs/pipeline.md:L42"
    E->>U: Final Answer (with citations)
```

---

## å¯èƒ½çš„å¢å¼ºæ–¹å‘

### ğŸ”¥ P0: å‡å°‘ LLM è°ƒç”¨æ¬¡æ•° (Reducing API Latency)

| æ–¹æ¡ˆ | é¢„æœŸæ•ˆæœ | å¤æ‚åº¦ |
|------|---------|--------|
| **åˆå¹¶ analyze + plan ä¸ºå•èŠ‚ç‚¹** | -1 call (3â†’2 per iteration) | ä½ |
| **è½»é‡çº§ grade è·³è¿‡** (context å‘½ä¸­ç‡é«˜æ—¶ç›´æ¥ GENERATE) | -1 call (å‘½ä¸­æ—¶) | ä½ |
| **streaming synthesize** | æ„ŸçŸ¥å»¶è¿Ÿé™ä½ 50%+ | ä¸­ |
| **å¹¶è¡Œå·¥å…·æ‰§è¡Œ** (tool_exec å†…éƒ¨å¹¶å‘) | å·¥å…·ç­‰å¾…æ—¶é—´å½’å¹¶ | ä¸­ |
| **LLM ç¼“å­˜** (ç›¸åŒ query+context ä¸é‡å¤è°ƒç”¨) | é‡å¤æŸ¥è¯¢ 0 call | ä¸­ |

### ğŸ¯ P1: æœç´¢è´¨é‡

| æ–¹æ¡ˆ | é¢„æœŸæ•ˆæœ | å¤æ‚åº¦ |
|------|---------|--------|
| **ä¸­æ–‡ BM25 åˆ†è¯** (jieba/pkuseg) | ä¸­æ–‡æ£€ç´¢å‡†ç¡®ç‡æå‡ | ä½ |
| **Reranker æ¨¡å‹** (BGE-reranker / Cohere) | æ›¿ä»£ LLM grading, æ›´å¿«æ›´ç²¾å‡† | ä¸­ |
| **Query Expansion** (åŒä¹‰è¯æ‰©å±•) | å¬å›ç‡æå‡ | ä½ |
| **Chunk overlap** (ç´¢å¼•æ—¶çª—å£é‡å ) | é˜²æ­¢è·¨ chunk ä¿¡æ¯ä¸¢å¤± | ä½ |

### ğŸ’¡ P2: ç”¨æˆ·ä½“éªŒ

| æ–¹æ¡ˆ | é¢„æœŸæ•ˆæœ | å¤æ‚åº¦ |
|------|---------|--------|
| **SSE Streaming** (é€ token è¾“å‡º) | é¦–å­—æ—¶é—´ <1s | é«˜ |
| **è¿›åº¦ç™¾åˆ†æ¯”** | ç”¨æˆ·çŸ¥é“å¤„äºç¬¬å‡ è½® | ä½ |
| **Source Preview** (ç‚¹å‡»å¼•ç”¨é¢„è§ˆåŸæ–‡) | å¢å¼ºå¯ä¿¡åº¦ | ä¸­ |
| **Feature Flag** (`KB_AGENT_USE_ADAPTIVE_RAG`) | æ–°æ—§æ¨¡å¼åˆ‡æ¢ | ä½ |

---

## File Map

```
src/kb_agent/agent/
â”œâ”€â”€ state.py     # AgentState TypedDict (17 fields)
â”œâ”€â”€ graph.py     # LangGraph æ‹“æ‰‘å®šä¹‰ (5 nodes, 6 edges)
â”œâ”€â”€ nodes.py     # 5 ä¸ª node å‡½æ•° + prompts (~800 lines)
â””â”€â”€ tools.py     # 9 ä¸ª @tool wrappers + hybrid_search RRF
```

## Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `KB_AGENT_MAX_ITERATIONS` | `3` | æœ€å¤§ planâ†’toolâ†’grade å¾ªç¯æ¬¡æ•° |
| `KB_AGENT_LLM_API_KEY` | - | LLM API å¯†é’¥ |
| `KB_AGENT_LLM_BASE_URL` | - | LLM ç«¯ç‚¹ URL |
| `KB_AGENT_LLM_MODEL` | - | æ¨¡å‹åç§° |
